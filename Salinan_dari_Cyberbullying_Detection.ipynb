{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Salinan dari Cyberbullying_Detection.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ysd_0cG3jW41"
      },
      "source": [
        "# Cyberbullying Detection\n",
        "Proses dibagi menjadi\n",
        "\n",
        "1.   Preprocessing \n",
        "2.   Feature Extraction\n",
        "3.   Classification\n",
        "4.   Evaluation\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_nvALDc3AHdF"
      },
      "source": [
        "#Data preparation\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ejt6xLsFi8Mx"
      },
      "source": [
        "Import Package yang dibutuhkan "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1nYjTbyiiU_O",
        "outputId": "26c3389e-2847-45c2-ca81-3ae42e3874d8"
      },
      "source": [
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "nltk.download('punkt')\n",
        "from nltk.corpus import stopwords #import stopwords\n",
        "from nltk.tokenize import RegexpTokenizer\n",
        "import re, string, unicodedata #import regular expression\n",
        "from nltk.corpus import stopwords \n",
        "from nltk.tokenize import word_tokenize\n",
        "import pandas as pd\n",
        "import csv"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0Bh_S73ci5gx"
      },
      "source": [
        "def casefolding(str):\n",
        "    new_str = str.lower()\n",
        "    return new_str\n",
        "\n",
        "def cleaning(str):\n",
        "    #melakukan masking terhadap url sehingga menjadi _url_\n",
        "    str =  re.sub(r'(?i)\\b((?:https?://|www\\d{0,3}[.]|[a-z0-9.\\-]+[.][a-z]{2,4}     /)(?:[^\\s()<>]+|\\(([^\\s()<>]+|(\\([^\\s()<>]+\\)))*\\))+(?:\\(([^\\s()<>]+|(\\([^\\s()<>]+\\)))*\\)|[^\\s`!()\\[\\]{};:\\'\".,<>?«»“”‘’]))', '', str)\n",
        "    str =str.replace('<br>','')\n",
        "    str = str.replace('</br>','')\n",
        "    str = re.sub(\"(@[A-Za-z0-9]+)|([^0-9A-Za-z \\t])|(\\w+:\\/\\/\\S+)\",\" \",str)\n",
        "    #remove punctuations\n",
        "    str = re.sub(r'[^\\w]|_',' ',str)\n",
        "    #remove digit from string\n",
        "    str = re.sub(\"\\S*\\d\\S*\", \"\", str).strip()\n",
        "    #removeHashtag\n",
        "    str = re.sub('#[^\\s]+','',str)\n",
        "    #remove non-ascii\n",
        "    str = unicodedata.normalize('NFKD', str).encode('ascii', 'ignore').decode('utf-8', 'ignore')\n",
        "    #to lowercase\n",
        "    str = str.lower()\n",
        "    #Remove additional white spaces\n",
        "    str = re.sub('[\\s]+', ' ', str)\n",
        "    return str\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GikFY06ejQ2K"
      },
      "source": [
        "def stopword(str):\n",
        "    stop_words = set(stopwords.words('english')) \n",
        "    word_tokens = word_tokenize(str) \n",
        "    filtered_sentence = [w for w in word_tokens if not w in stop_words]  \n",
        "    filtered_sentence = [] \n",
        "    for w in word_tokens: \n",
        "        if w not in stop_words: \n",
        "            filtered_sentence.append(w) \n",
        "    return(filtered_sentence)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nA2NjB6SjYHy"
      },
      "source": [
        "#remove sentence which contains only one word\n",
        "def removeSentence(str): \n",
        "    word = str.split()\n",
        "    wordCount = len(word)\n",
        "    if(wordCount<=1):\n",
        "        str = ''\n",
        "    \n",
        "    return str"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QmQvg1Mjje_2"
      },
      "source": [
        "def preprocessing (str):\n",
        "    str1 = casefolding(str)\n",
        "    str2 = cleaning(str1)\n",
        "    str3 = stopword(str2)\n",
        "    str4 = ' '.join(str3)\n",
        "    str5 = removeSentence(str4)\n",
        "    \n",
        "    return str5"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HtxSRvmzj-8P",
        "outputId": "3a6e71ee-4d24-4a37-91da-ae4db978a341"
      },
      "source": [
        "coba = ('@halalflaws @biebervalue @greenlinerzjm I read them in context.No change in meaning. The history of Islamic slavery. https://t.co/xWJzpSodGj')\n",
        "pre = preprocessing(coba)\n",
        "print(pre)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "read context change meaning history islamic slavery\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "whm36crvjuDj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "94e5b583-2c96-481b-af8d-fc6eb3277c9c"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount(\"/content/gdrive\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pu0fnY5wzWY3"
      },
      "source": [
        "fo = pd.read_csv('/content/gdrive/MyDrive/TUGAS NLP/twitter_parsed_dataset.csv')\n",
        "fo.Text=fo.Text.astype(str)\n",
        "review = fo['Text'].tolist()\n",
        "annotation = fo['Annotation'].tolist()\n",
        "def process(kata):\n",
        "    rv = []\n",
        "    for p in kata:\n",
        "        str = preprocessing(p)\n",
        "        rv.append(str)\n",
        "    return(rv)\n",
        "process = process(review)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 406
        },
        "id": "-XbNmdEjxFoE",
        "outputId": "7f03720c-8764-4278-caed-1c417e518853"
      },
      "source": [
        "bullying_textpreprocessing = {'Text':process,\n",
        "                              'Annotation' : annotation}\n",
        "df = pd.DataFrame(bullying_textpreprocessing )\n",
        "df['Annotation'] = df['Annotation'].replace(['none','sexism','racism'],[1, 2, 3])\n",
        "display(df)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Text</th>\n",
              "      <th>Annotation</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>read context change meaning history islamic sl...</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>idiots claim people tried stop becoming terror...</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>rt call sexist go auto place rather talk guy</td>\n",
              "      <td>2.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>wrong isis follows example mohammed quran exactly</td>\n",
              "      <td>3.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td></td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16846</th>\n",
              "      <td>feeling sorry girls safe kat andre going home mkr</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16847</th>\n",
              "      <td>mkr pretty good dishes happy ok well never eat...</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16848</th>\n",
              "      <td>rt deconstructed lemon tart please go one seas...</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16849</th>\n",
              "      <td>stupid talk blocked</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16850</th>\n",
              "      <td>protest mad much reason tweeting women feminism</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>16851 rows × 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                    Text  Annotation\n",
              "0      read context change meaning history islamic sl...         1.0\n",
              "1      idiots claim people tried stop becoming terror...         1.0\n",
              "2           rt call sexist go auto place rather talk guy         2.0\n",
              "3      wrong isis follows example mohammed quran exactly         3.0\n",
              "4                                                                1.0\n",
              "...                                                  ...         ...\n",
              "16846  feeling sorry girls safe kat andre going home mkr         1.0\n",
              "16847  mkr pretty good dishes happy ok well never eat...         1.0\n",
              "16848  rt deconstructed lemon tart please go one seas...         1.0\n",
              "16849                                stupid talk blocked         1.0\n",
              "16850    protest mad much reason tweeting women feminism         1.0\n",
              "\n",
              "[16851 rows x 2 columns]"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TlPIYP1tkzOk"
      },
      "source": [
        "# Feature Extraction\n",
        "\n",
        "\n",
        "*   TF-IDF\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tItMtrs8rWlg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9fa738df-a9b7-4f4d-cac0-fbc5761920b3"
      },
      "source": [
        "import numpy as np\n",
        "from imblearn.over_sampling import SMOTE\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from sklearn.preprocessing import LabelBinarizer\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer, TfidfTransformer"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/externals/six.py:31: FutureWarning: The module is deprecated in version 0.21 and will be removed in version 0.23 since we've dropped support for Python 2.7. Please rely on the official version of six (https://pypi.org/project/six/).\n",
            "  \"(https://pypi.org/project/six/).\", FutureWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/deprecation.py:144: FutureWarning: The sklearn.neighbors.base module is  deprecated in version 0.22 and will be removed in version 0.24. The corresponding classes / functions should instead be imported from sklearn.neighbors. Anything that cannot be imported from sklearn.neighbors is now part of the private API.\n",
            "  warnings.warn(message, FutureWarning)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cPAW0Aqg76JO"
      },
      "source": [
        "df.replace('', np.nan, inplace=True)\n",
        "df.dropna(inplace=True)\n",
        "none = df.loc[df['Annotation'] == 1, 'Text'].copy().reset_index(drop=True)\n",
        "sexism = df.loc[df['Annotation'] == 2, 'Text'].copy().reset_index(drop=True)\n",
        "racism = df.loc[df['Annotation'] == 3, 'Text'].copy().reset_index(drop=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fA2GFpuEq6rF",
        "outputId": "362972df-95dc-4858-b2f7-93528e319794"
      },
      "source": [
        "len(none), len(sexism), len(racism)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(10821, 3313, 1968)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RiFN40aMPJi0"
      },
      "source": [
        "y = df['Annotation']\n",
        "y=y.to_frame()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l7ScsazNrLJk"
      },
      "source": [
        "vect = TfidfVectorizer(max_features=15000, min_df=5, max_df=0.7)\n",
        "vector_transformer = vect.fit(df['Text'])\n",
        "vectorized_df = vector_transformer.transform(df['Text'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8bpzhughre79",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c66e2b13-ad38-4131-8437-58e3aec9a7cc"
      },
      "source": [
        "smote = SMOTE(random_state=777,k_neighbors=5)\n",
        "X_smote,y_smote = smote.fit_sample(vectorized_df,y)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:760: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
            "  warnings.warn(msg, category=FutureWarning)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UN6llXkMOaLN"
      },
      "source": [
        "X_trainSMOTE, X_valSMOTE, y_trainSMOTE, y_valSMOTE = train_test_split(X_smote, y_smote, test_size=0.2, random_state=0)\n",
        "X_trainSMOTE, X_testSMOTE, y_trainSMOTE, y_testSMOTE = train_test_split(X_trainSMOTE, y_trainSMOTE, test_size=0.25, random_state=0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uFmZcjWSGr5b"
      },
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(vectorized_df, df['Annotation'].values, test_size=0.2, random_state=42)\n",
        "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.25, random_state=42)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nSWXKOFGHMq2",
        "outputId": "53c51503-2b00-4242-990e-3c2cd1543397"
      },
      "source": [
        "X_train.shape, X_val.shape, X_test.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((9660, 3855), (3221, 3855), (3221, 3855))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D_g4gEDyHEf7",
        "outputId": "88bc28a9-36f9-4d49-b97b-c3db8ee111dc"
      },
      "source": [
        "X_trainSMOTE.shape, X_valSMOTE.shape, X_testSMOTE.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((19477, 3855), (6493, 3855), (6493, 3855))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DNRPVsxrlBE0"
      },
      "source": [
        "# Classification\n",
        "\n",
        "\n",
        "*   Deep Learning\n",
        "*   ML biasa (dipilih): Multinomial Naive Bayes, Linear Support Vector Classification (SVC) dan Logistic Regression (LR)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "alKGhCjwsDn1"
      },
      "source": [
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.svm import LinearSVC\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "import sklearn.svm as svm\n",
        "from nltk.tokenize import sent_tokenize \n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.metrics import classification_report\n",
        "import pickle"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gTEzlHQdFmCB"
      },
      "source": [
        "#ML w/o SMOTE"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WIb6KMMHFlo2",
        "outputId": "55b91750-cf2d-4bfe-856e-fa6a528eda79"
      },
      "source": [
        "nb = MultinomialNB()\n",
        "nb.fit(X_train, y_train)\n",
        "predval_nb = nb.predict(X_val)\n",
        "print('Accuracy %s' % accuracy_score(predval_nb,y_val))\n",
        "print(classification_report(y_val,predval_nb))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy 0.7929214529649177\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         1.0       0.78      0.96      0.86      2186\n",
            "         2.0       0.88      0.38      0.53       664\n",
            "         3.0       0.81      0.53      0.64       371\n",
            "\n",
            "    accuracy                           0.79      3221\n",
            "   macro avg       0.82      0.62      0.68      3221\n",
            "weighted avg       0.80      0.79      0.77      3221\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m58NXnp4HyBZ",
        "outputId": "6c41c5bc-77fc-4725-9714-f2a067cbf7aa"
      },
      "source": [
        "pred_nb = nb.predict(X_test)\n",
        "print('Accuracy %s' % accuracy_score(pred_nb,y_test))\n",
        "print(classification_report(y_test, pred_nb))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy 0.7926109903756597\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         1.0       0.78      0.96      0.86      2156\n",
            "         2.0       0.90      0.39      0.55       672\n",
            "         3.0       0.78      0.58      0.66       393\n",
            "\n",
            "    accuracy                           0.79      3221\n",
            "   macro avg       0.82      0.64      0.69      3221\n",
            "weighted avg       0.81      0.79      0.77      3221\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wyFtLtNmIOKB"
      },
      "source": [
        "filenameNB = 'Multinomial NB without SMOTE.sav'\n",
        "pickle.dump(nb, open(filenameNB, 'wb'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cRIj-E23IDeG",
        "outputId": "116dfda9-fdbb-45ce-d02b-64579e56fb50"
      },
      "source": [
        "clf_svm = svm.LinearSVC()\n",
        "clf_svm.fit(X_trainSMOTE, y_trainSMOTE)\n",
        "pred_svm = clf_svm.predict(X_valSMOTE)\n",
        "print('Accuracy %s' % accuracy_score(pred_svm,y_valSMOTE))\n",
        "print(classification_report(y_valSMOTE,pred_svm))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy 0.8851070383489912\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         1.0       0.87      0.77      0.82      2130\n",
            "         2.0       0.85      0.90      0.88      2230\n",
            "         3.0       0.93      0.99      0.96      2133\n",
            "\n",
            "    accuracy                           0.89      6493\n",
            "   macro avg       0.88      0.88      0.88      6493\n",
            "weighted avg       0.88      0.89      0.88      6493\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lPkhZKG_JXSf",
        "outputId": "7c1db198-c384-4294-a7e9-b6105b51a5d2"
      },
      "source": [
        "clf_svm = svm.LinearSVC()\n",
        "clf_svm.fit(X_train, y_train)\n",
        "pred_svm = clf_svm.predict(X_val)\n",
        "print('Accuracy %s' % accuracy_score(pred_svm,y_val))\n",
        "print(classification_report(y_val,pred_svm))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy 0.8149642968022354\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         1.0       0.83      0.91      0.87      2186\n",
            "         2.0       0.78      0.58      0.66       664\n",
            "         3.0       0.74      0.66      0.70       371\n",
            "\n",
            "    accuracy                           0.81      3221\n",
            "   macro avg       0.79      0.72      0.75      3221\n",
            "weighted avg       0.81      0.81      0.81      3221\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ls4n3z0tLVqY",
        "outputId": "864b59e9-a398-4715-b821-cdc9a8e6fa0f"
      },
      "source": [
        "predtest_svm = clf_svm.predict(X_test)\n",
        "print('Accuracy %s' % accuracy_score(predtest_svm,y_test))\n",
        "print(classification_report(y_test,predtest_svm))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy 0.8096864327848494\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         1.0       0.83      0.90      0.86      2156\n",
            "         2.0       0.76      0.59      0.67       672\n",
            "         3.0       0.74      0.69      0.71       393\n",
            "\n",
            "    accuracy                           0.81      3221\n",
            "   macro avg       0.78      0.73      0.75      3221\n",
            "weighted avg       0.81      0.81      0.80      3221\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9NdsOD2EMijO"
      },
      "source": [
        "filenameSVM = 'SVM.sav'\n",
        "pickle.dump(clf_svm, open(filenameSVM, 'wb'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CNs17BnSMpjm",
        "outputId": "b5705139-7e9d-42e0-ff46-c225a4a73bdd"
      },
      "source": [
        "logReg = LogisticRegression(C=0.2, dual=False)\n",
        "logReg.fit(X_train, y_train)\n",
        "predval_logreg = logReg.predict(X_val)\n",
        "print('Accuracy %s' % accuracy_score(predval_logreg,y_val))\n",
        "print(classification_report(y_val,predval_logreg))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy 0.778329711269792\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         1.0       0.77      0.97      0.86      2186\n",
            "         2.0       0.91      0.36      0.52       664\n",
            "         3.0       0.78      0.39      0.52       371\n",
            "\n",
            "    accuracy                           0.78      3221\n",
            "   macro avg       0.82      0.57      0.63      3221\n",
            "weighted avg       0.80      0.78      0.75      3221\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "20WYeNrcM_t6",
        "outputId": "d472cc4d-204c-4787-b51e-dfb7d8d887e8"
      },
      "source": [
        "predtest_logreg = logReg.predict(X_test)\n",
        "print('Accuracy %s' % accuracy_score(predtest_logreg,y_test))\n",
        "print(classification_report(y_test,predtest_logreg))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy 0.7755355479664701\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         1.0       0.76      0.97      0.85      2156\n",
            "         2.0       0.89      0.38      0.53       672\n",
            "         3.0       0.79      0.41      0.54       393\n",
            "\n",
            "    accuracy                           0.78      3221\n",
            "   macro avg       0.81      0.58      0.64      3221\n",
            "weighted avg       0.79      0.78      0.75      3221\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b8afZ2BpNK2W"
      },
      "source": [
        "filenameLogReg = 'Logostic Regression.sav'\n",
        "pickle.dump(logReg, open(filenameLogReg, 'wb'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sPW9qWBqkYEE",
        "outputId": "c813ea1f-5176-4a12-8c02-8046f772153c"
      },
      "source": [
        "def predictor(sentence):\n",
        "    sent = sent_tokenize(sentence)\n",
        "    y = vector_transformer.transform(sent)\n",
        " #   y_pred = nb.predict(y)\n",
        "    loaded_model = pickle.load(open(filenameSVM, 'rb'))\n",
        "    y_pred = loaded_model.predict(y)\n",
        "    if y_pred == 1:\n",
        "      return ('none')  \n",
        "\n",
        "    elif y_pred  == 2:\n",
        "        return('sexism')\n",
        "\n",
        "    elif y_pred == 3:\n",
        "        return('racism')\n",
        "\n",
        "stc = input('Enter tweet : ')\n",
        "print(predictor(stc))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Enter tweet : i hate muslim\n",
            "racism\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d0x1OoEKFbOO"
      },
      "source": [
        "#ML SMOTE"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5CYxE0DGStRY",
        "outputId": "665e1fe2-f45d-4f35-ced2-a20a469fe685"
      },
      "source": [
        "nbSMOTE = MultinomialNB()\n",
        "nbSMOTE.fit(X_trainSMOTE, y_trainSMOTE)\n",
        "predvalSMOTE_nb = nbSMOTE.predict(X_valSMOTE)\n",
        "print('Accuracy %s' % accuracy_score(predvalSMOTE_nb,y_valSMOTE))\n",
        "print(classification_report(y_valSMOTE,predvalSMOTE_nb))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy 0.8295087016787309\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         1.0       0.79      0.70      0.74      2130\n",
            "         2.0       0.83      0.82      0.82      2230\n",
            "         3.0       0.87      0.97      0.92      2133\n",
            "\n",
            "    accuracy                           0.83      6493\n",
            "   macro avg       0.83      0.83      0.83      6493\n",
            "weighted avg       0.83      0.83      0.83      6493\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VyJGLsfZqRJy",
        "outputId": "fa0b8abe-a7ed-4fcc-9109-8bce0f255023"
      },
      "source": [
        "pred_nbSMOTE = nbSMOTE.predict(X_testSMOTE)\n",
        "print('Accuracy %s' % accuracy_score(pred_nbSMOTE,y_testSMOTE))\n",
        "print(classification_report(y_testSMOTE,pred_nbSMOTE))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy 0.8348991221315263\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         1.0       0.79      0.71      0.75      2119\n",
            "         2.0       0.83      0.82      0.83      2203\n",
            "         3.0       0.87      0.97      0.92      2171\n",
            "\n",
            "    accuracy                           0.83      6493\n",
            "   macro avg       0.83      0.83      0.83      6493\n",
            "weighted avg       0.83      0.83      0.83      6493\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SH9sDNqwAY4l"
      },
      "source": [
        "filenameNBSMOTE = 'Multinomial NB with SMOTE.sav'\n",
        "pickle.dump(nbSMOTE, open(filenameNBSMOTE, 'wb'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Lt-93xxH7nkm",
        "outputId": "f2ac680c-be84-41e6-f27d-414e85281423"
      },
      "source": [
        "clf_svmSMOTE = svm.LinearSVC()\n",
        "clf_svmSMOTE.fit(X_trainSMOTE, y_trainSMOTE)\n",
        "predval_svmSMOTE = clf_svmSMOTE.predict(X_valSMOTE)\n",
        "print('Accuracy %s' % accuracy_score(predval_svmSMOTE,y_valSMOTE))\n",
        "print(classification_report(y_valSMOTE,predval_svmSMOTE))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy 0.8851070383489912\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         1.0       0.87      0.77      0.82      2130\n",
            "         2.0       0.85      0.90      0.88      2230\n",
            "         3.0       0.93      0.99      0.96      2133\n",
            "\n",
            "    accuracy                           0.89      6493\n",
            "   macro avg       0.88      0.88      0.88      6493\n",
            "weighted avg       0.88      0.89      0.88      6493\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R_NqJ4yiOSEA",
        "outputId": "6fabf21d-260e-4d88-b269-6bf09a85c52d"
      },
      "source": [
        "predtest_svmSMOTE = clf_svmSMOTE.predict(X_testSMOTE)\n",
        "print('Accuracy %s' % accuracy_score(predtest_svmSMOTE,y_testSMOTE))\n",
        "print(classification_report(y_testSMOTE,predtest_svmSMOTE))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy 0.8807947019867549\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         1.0       0.86      0.76      0.81      2119\n",
            "         2.0       0.85      0.90      0.87      2203\n",
            "         3.0       0.93      0.97      0.95      2171\n",
            "\n",
            "    accuracy                           0.88      6493\n",
            "   macro avg       0.88      0.88      0.88      6493\n",
            "weighted avg       0.88      0.88      0.88      6493\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7h1Ilwg8OfkY"
      },
      "source": [
        "filenameSVMSMOTE = 'SVM with SMOTE.sav'\n",
        "pickle.dump(clf_svmSMOTE, open(filenameSVMSMOTE, 'wb'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EAKM3U318yan",
        "outputId": "01d62f51-a7d2-4117-f3fc-2466ffd29480"
      },
      "source": [
        "logReg = LogisticRegression(C=0.2, dual=False)\n",
        "logReg.fit(X_trainSMOTE, y_trainSMOTE)\n",
        "predval_logreg = logReg.predict(X_valSMOTE)\n",
        "print('Accuracy %s' % accuracy_score(predval_logreg,y_valSMOTE))\n",
        "print(classification_report(y_valSMOTE,predval_logreg))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy 0.8600030802402587\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         1.0       0.80      0.79      0.79      2130\n",
            "         2.0       0.85      0.86      0.85      2230\n",
            "         3.0       0.94      0.93      0.93      2133\n",
            "\n",
            "    accuracy                           0.86      6493\n",
            "   macro avg       0.86      0.86      0.86      6493\n",
            "weighted avg       0.86      0.86      0.86      6493\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X3h0DBIPq7Kv",
        "outputId": "cc47c3e6-a44e-470c-f2a4-382e6178e598"
      },
      "source": [
        "pred_logreg = logReg.predict(X_testSMOTE)\n",
        "print('Accuracy %s' % accuracy_score(pred_logreg,y_testSMOTE))\n",
        "print(classification_report(y_testSMOTE,pred_logreg))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy 0.8529185276451563\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         1.0       0.78      0.78      0.78      2119\n",
            "         2.0       0.84      0.85      0.85      2203\n",
            "         3.0       0.93      0.93      0.93      2171\n",
            "\n",
            "    accuracy                           0.85      6493\n",
            "   macro avg       0.85      0.85      0.85      6493\n",
            "weighted avg       0.85      0.85      0.85      6493\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0rVNFuRbCiPr"
      },
      "source": [
        "filenamelogReg = 'Logistic Regression with SMOTE.sav'\n",
        "pickle.dump(logReg, open(filenamelogReg, 'wb'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rgXxYyZ8bJyC",
        "outputId": "12d88a4c-9a5c-47c0-b3aa-45bd1bb3a1dc"
      },
      "source": [
        "def predictor_SMOTE(sentence):\n",
        "    sent = sent_tokenize(sentence)\n",
        "    y = vector_transformer.transform(sent)\n",
        " #   y_pred = nb.predict(y)\n",
        "    loaded_model = pickle.load(open(filenameSVMSMOTE, 'rb'))\n",
        "    y_pred = loaded_model.predict(y)\n",
        "    if y_pred == 1:\n",
        "      return ('none')  \n",
        "\n",
        "    elif y_pred  == 2:\n",
        "        return('sexism')\n",
        "\n",
        "    elif y_pred == 3:\n",
        "        return('racism')\n",
        "\n",
        "stc = input('Enter tweet : ')\n",
        "print(predictor_SMOTE(stc))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Enter tweet : i hate muslim\n",
            "racism\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n_Hh0O459tQL"
      },
      "source": [
        "Deep Learning w/o SMOTE"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FREQ4i113eNh"
      },
      "source": [
        "from sklearn.preprocessing import LabelEncoder\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.preprocessing import sequence\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from keras.models import Sequential\n",
        "from keras import regularizers\n",
        "from keras.layers import LSTM, Conv1D, MaxPooling1D, Activation, Dense, Dropout, Input, Embedding, Bidirectional, GlobalMaxPool1D"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2a76DyUZYI9y"
      },
      "source": [
        "# 3 news groups\n",
        "num_labels = 3\n",
        "vocab_size = 15000\n",
        "batch_size = 100\n",
        "num_epochs = 10"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ld-KBUPAwYnI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a52186b6-72a2-4db2-a5ba-5bd15dd47c80"
      },
      "source": [
        "train_size = int(len(df) * .6)\n",
        "test_size = int(len(df)* .2)\n",
        "val_size = int(len(df)* .2)\n",
        "train_size, test_size, val_size"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(9661, 3220, 3220)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6xc4OdKp9_cL"
      },
      "source": [
        "train_posts = df['Text'][:train_size]\n",
        "train_tags = df['Annotation'][:train_size]\n",
        "\n",
        "test_posts = df['Text'][:test_size]\n",
        "test_tags = df['Annotation'][:test_size]\n",
        "\n",
        "val_posts = df['Text'][:val_size]\n",
        "val_tags = df['Annotation'][:val_size]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yoGvJOQt7GCX",
        "outputId": "3a02805f-35b2-45d4-c8c4-7a3f18eb8509"
      },
      "source": [
        "type(test_posts)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "pandas.core.series.Series"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a1dOdW3dYnxg",
        "outputId": "ea9538f5-e76c-49e4-c528-dce339d86988"
      },
      "source": [
        "len(train_tags), type(test_tags), len(val_tags)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(9661, pandas.core.series.Series, 3220)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h8KqcWmPapNC"
      },
      "source": [
        "tokenizer_obj = Tokenizer()\n",
        "tokenizer_obj.fit_on_texts(train_posts) \n",
        "\n",
        "# pad sequences\n",
        "max_length = max([len(s.split()) for s in train_posts])\n",
        "\n",
        "\n",
        "# define vocabulary size\n",
        "vocab_size = len(tokenizer_obj.word_index) + 1\n",
        "\n",
        "X_train_tokens =  tokenizer_obj.texts_to_sequences(train_posts)\n",
        "X_test_tokens = tokenizer_obj.texts_to_sequences(test_posts)\n",
        "X_val_tokens = tokenizer_obj.texts_to_sequences(val_posts)\n",
        "\n",
        "X_train_pad = pad_sequences(X_train_tokens, maxlen=max_length, padding='post')\n",
        "X_test_pad = pad_sequences(X_test_tokens, maxlen=max_length, padding='post')\n",
        "X_val_pad = pad_sequences(X_val_tokens, maxlen=max_length, padding='post')\n",
        "\n",
        "encoder = LabelBinarizer()\n",
        "encoder.fit(train_tags)\n",
        "y_trainDL = encoder.transform(train_tags)\n",
        "y_testDL = encoder.transform(test_tags)\n",
        "y_valDL = encoder.transform(val_tags)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kkBaq7g1AxV7",
        "outputId": "1b195bf0-b770-49c7-9d77-5dd516737882"
      },
      "source": [
        "type(X_train_tokens)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "list"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6PBqYRXBZ8zT",
        "outputId": "35249525-dd83-4b25-aed1-8a612a177ae2"
      },
      "source": [
        "X_train_pad.shape, y_trainDL.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((9661, 21), (9661, 3))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Vg_ww1dvaCp0",
        "outputId": "c1f8a5e7-46d2-49af-9471-5315f298c6d1"
      },
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Embedding, LSTM, GRU\n",
        "from keras.layers.embeddings import Embedding\n",
        "\n",
        "EMBEDDING_DIM = 100\n",
        "def build_model(vocab_size, EMBEDDING_DIM, max_length):\n",
        "  print('Build model...')\n",
        "\n",
        "  model = Sequential()\n",
        "  model.add(Embedding(vocab_size, EMBEDDING_DIM, input_length=max_length))\n",
        "  model.add(GRU(units=32,  dropout=0.2, recurrent_dropout=0.2))\n",
        "  model.add(Dense(num_labels, activation='softmax'))\n",
        "\n",
        "  # try using different optimizers and different optimizer configs\n",
        "  \n",
        "  model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "  return model\n",
        "print('Summary of the built model...')\n",
        "model = build_model(vocab_size=vocab_size, EMBEDDING_DIM=EMBEDDING_DIM, max_length=max_length)\n",
        "print(model.summary())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Summary of the built model...\n",
            "Build model...\n",
            "WARNING:tensorflow:Layer gru will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n",
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding (Embedding)        (None, 21, 100)           1239400   \n",
            "_________________________________________________________________\n",
            "gru (GRU)                    (None, 32)                12864     \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 3)                 99        \n",
            "=================================================================\n",
            "Total params: 1,252,363\n",
            "Trainable params: 1,252,363\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4mdqneBtaK3N",
        "outputId": "05f9a522-3d02-4e73-e39d-3ebf66199d05"
      },
      "source": [
        "num_epochs =10\n",
        "batch_size = 128\n",
        "history = model.fit(X_train_pad, y_trainDL,\n",
        "                    batch_size=batch_size,\n",
        "                    epochs=num_epochs,\n",
        "                    verbose=2,\n",
        "                    validation_data = [X_val_pad, y_valDL])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "76/76 - 14s - loss: 0.8800 - accuracy: 0.6687 - val_loss: 0.0000e+00 - val_accuracy: 0.0000e+00\n",
            "Epoch 2/10\n",
            "76/76 - 9s - loss: 0.8327 - accuracy: 0.6706 - val_loss: 0.0000e+00 - val_accuracy: 0.0000e+00\n",
            "Epoch 3/10\n",
            "76/76 - 9s - loss: 0.5821 - accuracy: 0.7480 - val_loss: 0.0000e+00 - val_accuracy: 0.0000e+00\n",
            "Epoch 4/10\n",
            "76/76 - 9s - loss: 0.4149 - accuracy: 0.8465 - val_loss: 0.0000e+00 - val_accuracy: 0.0000e+00\n",
            "Epoch 5/10\n",
            "76/76 - 9s - loss: 0.2267 - accuracy: 0.9255 - val_loss: 0.0000e+00 - val_accuracy: 0.0000e+00\n",
            "Epoch 6/10\n",
            "76/76 - 9s - loss: 0.1509 - accuracy: 0.9509 - val_loss: 0.0000e+00 - val_accuracy: 0.0000e+00\n",
            "Epoch 7/10\n",
            "76/76 - 9s - loss: 0.1121 - accuracy: 0.9660 - val_loss: 0.0000e+00 - val_accuracy: 0.0000e+00\n",
            "Epoch 8/10\n",
            "76/76 - 9s - loss: 0.0950 - accuracy: 0.9705 - val_loss: 0.0000e+00 - val_accuracy: 0.0000e+00\n",
            "Epoch 9/10\n",
            "76/76 - 9s - loss: 0.0752 - accuracy: 0.9773 - val_loss: 0.0000e+00 - val_accuracy: 0.0000e+00\n",
            "Epoch 10/10\n",
            "76/76 - 9s - loss: 0.0628 - accuracy: 0.9802 - val_loss: 0.0000e+00 - val_accuracy: 0.0000e+00\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BFEOm8arbQAl",
        "outputId": "456161b6-7b53-44d0-ab2e-2445462cfbb5"
      },
      "source": [
        "score,acc= model.evaluate(X_test_pad, y_testDL, \n",
        "                          batch_size = batch_size, verbose = 2)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "26/26 - 1s - loss: 0.0340 - accuracy: 0.9907\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-zMKrkdxxG3p",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6c3bc5c1-3cbd-4a13-c865-a431a1381076"
      },
      "source": [
        "type(X_test_pad)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "numpy.ndarray"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 54
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NjT5eyOSZHhz",
        "outputId": "126620c5-471e-49b5-dd2b-8a06854bc203"
      },
      "source": [
        "model.save(\"model.h5\")\n",
        "print(\"Saved model to disk\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Saved model to disk\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K5BCVM0bkcvK"
      },
      "source": [
        "import tensorflow as tf\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XcV5XdnQ7km5",
        "outputId": "f581576c-3edb-4c39-ff6e-8a73e0153f0d"
      },
      "source": [
        "def predict_DL(s):\n",
        "  s = sent_tokenize(s)\n",
        "  text_labels = encoder.classes_\n",
        "  X_tokens = tokenizer_obj.texts_to_sequences(s)\n",
        "  X_pad = pad_sequences(X_tokens, maxlen=max_length, padding='post')\n",
        "  loaded_model= tf.keras.models.load_model('model.h5')\n",
        "  predictions = model.predict(np.array(X_pad))\n",
        "  predicted_label = text_labels[np.argmax(predictions[0])]\n",
        "  if predicted_label == 1.0:\n",
        "    return ('none')  \n",
        "\n",
        "  elif predicted_label  == 2.0:\n",
        "      return('sexism')\n",
        "\n",
        "  elif predicted_label == 3.0:\n",
        "      return('racism')\n",
        "\n",
        "s = input('Enter tweet : ')\n",
        "print(predict_DL(s))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Enter tweet : i hate muslim\n",
            "WARNING:tensorflow:Layer gru will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n",
            "racism\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3KaVa8499gbJ"
      },
      "source": [
        "Deep Learning SMOTE"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CLO57puY3oXV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e95ffece-fb30-4fbe-cc66-cbcfd4cc11ec"
      },
      "source": [
        "smote = SMOTE('minority')\n",
        "X_sm, y_sm = smote.fit_sample(X_train_pad, y_trainDL)\n",
        "print(X_sm.shape, y_sm.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(14940, 21) (14940, 3)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
            "  warnings.warn(msg, category=FutureWarning)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_MVI7jcZdTmb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c9ad1386-98f0-43de-fe47-b4beeaeb2858"
      },
      "source": [
        "y_train_labels = np.array(train_tags)\n",
        "np.unique(y_train_labels)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1., 2., 3.])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 60
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bWE-bBDvMWEP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "56d60cb5-6be9-4fa3-b071-2312fc4e25c6"
      },
      "source": [
        "y_test_labels = np.array(test_tags)\n",
        "np.unique(y_test_labels)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1., 2., 3.])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 61
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wm3fQvs2kyUj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b9eb1f81-ba82-4995-8316-9a4f9972b714"
      },
      "source": [
        "modelSMOTE = build_model(vocab_size=vocab_size, EMBEDDING_DIM=EMBEDDING_DIM, max_length=max_length)\n",
        "print(modelSMOTE.summary())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Build model...\n",
            "WARNING:tensorflow:Layer gru_2 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n",
            "Model: \"sequential_4\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_4 (Embedding)      (None, 21, 100)           1239400   \n",
            "_________________________________________________________________\n",
            "gru_2 (GRU)                  (None, 32)                12864     \n",
            "_________________________________________________________________\n",
            "dense_4 (Dense)              (None, 3)                 99        \n",
            "=================================================================\n",
            "Total params: 1,252,363\n",
            "Trainable params: 1,252,363\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rGGP3LIPdBfv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b2566116-4ce2-4df6-e669-9dd8d391529b"
      },
      "source": [
        "from sklearn.utils import class_weight\n",
        "class_weight = class_weight.compute_sample_weight(\"balanced\", np.unique(y_train_labels))\n",
        "num_epochs =10\n",
        "batch_size = 128\n",
        "history_SMOTE = modelSMOTE.fit(X_sm, y_sm,\n",
        "                    batch_size=batch_size,\n",
        "                    epochs=num_epochs,\n",
        "                    verbose=2,\n",
        "                    #class_weight=class_weight,\n",
        "                    validation_data = [X_val_pad, y_testDL])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "117/117 - 16s - loss: 1.0000 - accuracy: 0.4321 - val_loss: 0.0000e+00 - val_accuracy: 0.0000e+00\n",
            "Epoch 2/10\n",
            "117/117 - 13s - loss: 0.9626 - accuracy: 0.4699 - val_loss: 0.0000e+00 - val_accuracy: 0.0000e+00\n",
            "Epoch 3/10\n",
            "117/117 - 13s - loss: 0.6624 - accuracy: 0.7062 - val_loss: 0.0000e+00 - val_accuracy: 0.0000e+00\n",
            "Epoch 4/10\n",
            "117/117 - 13s - loss: 0.4590 - accuracy: 0.8258 - val_loss: 0.0000e+00 - val_accuracy: 0.0000e+00\n",
            "Epoch 5/10\n",
            "117/117 - 13s - loss: 0.3168 - accuracy: 0.8912 - val_loss: 0.0000e+00 - val_accuracy: 0.0000e+00\n",
            "Epoch 6/10\n",
            "117/117 - 13s - loss: 0.2328 - accuracy: 0.9235 - val_loss: 0.0000e+00 - val_accuracy: 0.0000e+00\n",
            "Epoch 7/10\n",
            "117/117 - 13s - loss: 0.1781 - accuracy: 0.9437 - val_loss: 0.0000e+00 - val_accuracy: 0.0000e+00\n",
            "Epoch 8/10\n",
            "117/117 - 13s - loss: 0.1418 - accuracy: 0.9549 - val_loss: 0.0000e+00 - val_accuracy: 0.0000e+00\n",
            "Epoch 9/10\n",
            "117/117 - 13s - loss: 0.1111 - accuracy: 0.9655 - val_loss: 0.0000e+00 - val_accuracy: 0.0000e+00\n",
            "Epoch 10/10\n",
            "117/117 - 13s - loss: 0.0898 - accuracy: 0.9727 - val_loss: 0.0000e+00 - val_accuracy: 0.0000e+00\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P1OJcV2Q3rWR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fd4d9a91-1cca-4839-d6f9-e2b16ed320e4"
      },
      "source": [
        "score1,acc1= modelSMOTE.evaluate(X_test_pad, y_testDL, \n",
        "                          batch_size = batch_size, verbose = 2)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "26/26 - 1s - loss: 0.0557 - accuracy: 0.9839\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "182SaBjD8mUj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f55c4c44-9e08-4d57-9653-13bb88d181a0"
      },
      "source": [
        "modelSMOTE.save(\"modelSMOTE.h5\")\n",
        "print(\"Saved model to disk\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Saved model to disk\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "phY9Qnr2y6WN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e03270a4-b22d-47b6-fc6d-b732256369d6"
      },
      "source": [
        "def predictSMOTE_DL(s):\n",
        "  s = sent_tokenize(s)\n",
        "  text_labels = encoder.classes_\n",
        "  X_tokens = tokenizer_obj.texts_to_sequences(s)\n",
        "  X_pad = pad_sequences(X_tokens, maxlen=max_length, padding='post')\n",
        "  loaded_model= tf.keras.models.load_model('modelSMOTE.h5')\n",
        "  predictions = model.predict(np.array(X_pad))\n",
        "  predicted_label = text_labels[np.argmax(predictions[0])]\n",
        "  if predicted_label == 1.0:\n",
        "    return ('none')  \n",
        "\n",
        "  elif predicted_label  == 2.0:\n",
        "      return('sexism')\n",
        "\n",
        "  elif predicted_label == 3.0:\n",
        "      return('racism')\n",
        "\n",
        "s = input('Enter tweet : ')\n",
        "print(predictSMOTE_DL(s))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Enter tweet : i hate muslim\n",
            "WARNING:tensorflow:Layer gru_2 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n",
            "racism\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0Y5KD-j8lReQ"
      },
      "source": [
        "Deep Learning LSTM w/o SMOTE\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oP9EgXMglPud",
        "outputId": "ef428e65-4ed8-48a1-ae86-0d4235c9fe47"
      },
      "source": [
        "def build_modelLSTM(vocab_size, EMBEDDING_DIM, max_length):\n",
        "  print('Build model...')\n",
        "\n",
        "  model = Sequential()\n",
        "  model.add(Embedding(vocab_size, EMBEDDING_DIM, input_length=max_length))\n",
        "  model.add(LSTM(units=32,  dropout=0.2, recurrent_dropout=0.2))\n",
        "  model.add(Dense(num_labels, activation='softmax'))\n",
        "\n",
        "  # try using different optimizers and different optimizer configs\n",
        "  \n",
        "  model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "  return model\n",
        "print('Summary of the built model...')\n",
        "modelLSTM = build_modelLSTM(vocab_size=vocab_size, EMBEDDING_DIM=EMBEDDING_DIM, max_length=max_length)\n",
        "print(modelLSTM.summary())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Summary of the built model...\n",
            "Build model...\n",
            "WARNING:tensorflow:Layer lstm will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n",
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_2 (Embedding)      (None, 21, 100)           1239400   \n",
            "_________________________________________________________________\n",
            "lstm (LSTM)                  (None, 32)                17024     \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 3)                 99        \n",
            "=================================================================\n",
            "Total params: 1,256,523\n",
            "Trainable params: 1,256,523\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YYNd_GxKmL3E",
        "outputId": "0f48c54e-5b9b-4ab6-f224-d301393deeff"
      },
      "source": [
        "num_epochs =10\n",
        "batch_size = 128\n",
        "historyLSTM = modelLSTM.fit(X_train_pad, y_trainDL,\n",
        "                    batch_size=batch_size,\n",
        "                    epochs=num_epochs,\n",
        "                    verbose=2,\n",
        "                    validation_data = [X_val_pad, y_valDL])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "76/76 - 13s - loss: 0.8752 - accuracy: 0.6630 - val_loss: 0.0000e+00 - val_accuracy: 0.0000e+00\n",
            "Epoch 2/10\n",
            "76/76 - 10s - loss: 0.5075 - accuracy: 0.7989 - val_loss: 0.0000e+00 - val_accuracy: 0.0000e+00\n",
            "Epoch 3/10\n",
            "76/76 - 9s - loss: 0.2675 - accuracy: 0.9044 - val_loss: 0.0000e+00 - val_accuracy: 0.0000e+00\n",
            "Epoch 4/10\n",
            "76/76 - 9s - loss: 0.1754 - accuracy: 0.9416 - val_loss: 0.0000e+00 - val_accuracy: 0.0000e+00\n",
            "Epoch 5/10\n",
            "76/76 - 9s - loss: 0.1270 - accuracy: 0.9563 - val_loss: 0.0000e+00 - val_accuracy: 0.0000e+00\n",
            "Epoch 6/10\n",
            "76/76 - 9s - loss: 0.0997 - accuracy: 0.9658 - val_loss: 0.0000e+00 - val_accuracy: 0.0000e+00\n",
            "Epoch 7/10\n",
            "76/76 - 9s - loss: 0.0838 - accuracy: 0.9739 - val_loss: 0.0000e+00 - val_accuracy: 0.0000e+00\n",
            "Epoch 8/10\n",
            "76/76 - 9s - loss: 0.0723 - accuracy: 0.9761 - val_loss: 0.0000e+00 - val_accuracy: 0.0000e+00\n",
            "Epoch 9/10\n",
            "76/76 - 10s - loss: 0.0616 - accuracy: 0.9793 - val_loss: 0.0000e+00 - val_accuracy: 0.0000e+00\n",
            "Epoch 10/10\n",
            "76/76 - 9s - loss: 0.0548 - accuracy: 0.9827 - val_loss: 0.0000e+00 - val_accuracy: 0.0000e+00\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "32m0o7zkmXwH",
        "outputId": "92270ac7-d1c2-44f8-8486-4df0c5896a47"
      },
      "source": [
        "scoreLSTM,accLSTN= modelLSTM.evaluate(X_test_pad, y_testDL, \n",
        "                          batch_size = batch_size, verbose = 2)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "26/26 - 1s - loss: 0.0367 - accuracy: 0.9882\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YMD9fHtwmlBx",
        "outputId": "6f021f0b-214c-4b78-d7ac-d0a0dc2c0906"
      },
      "source": [
        "modelLSTM.save(\"modelLSTM.h5\")\n",
        "print(\"Saved model to disk\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Saved model to disk\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X6jeN5UFm-_q",
        "outputId": "60edc426-bb48-40ac-87c8-ac26f8aeb381"
      },
      "source": [
        "def predict_DLLSTM(s):\n",
        "  s = sent_tokenize(s)\n",
        "  text_labels = encoder.classes_\n",
        "  X_tokens = tokenizer_obj.texts_to_sequences(s)\n",
        "  X_pad = pad_sequences(X_tokens, maxlen=max_length, padding='post')\n",
        "  loaded_model= tf.keras.models.load_model('modelLSTM.h5')\n",
        "  predictions = model.predict(np.array(X_pad))\n",
        "  predicted_label = text_labels[np.argmax(predictions[0])]\n",
        "  if predicted_label == 1.0:\n",
        "    return ('none')  \n",
        "\n",
        "  elif predicted_label  == 2.0:\n",
        "      return('sexism')\n",
        "\n",
        "  elif predicted_label == 3.0:\n",
        "      return('racism')\n",
        "\n",
        "s = input('Enter tweet : ')\n",
        "print(predict_DL(s))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Enter tweet : i hate muslim\n",
            "WARNING:tensorflow:Layer gru will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n",
            "racism\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KjEp8DTtnKie",
        "outputId": "243c53a5-6a4c-48f1-b0d3-0e9e17b2ddab"
      },
      "source": [
        "modelSMOTELSTM = build_modelLSTM(vocab_size=vocab_size, EMBEDDING_DIM=EMBEDDING_DIM, max_length=max_length)\n",
        "print(modelSMOTELSTM.summary())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Build model...\n",
            "WARNING:tensorflow:Layer lstm_1 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n",
            "Model: \"sequential_3\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_3 (Embedding)      (None, 21, 100)           1239400   \n",
            "_________________________________________________________________\n",
            "lstm_1 (LSTM)                (None, 32)                17024     \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 3)                 99        \n",
            "=================================================================\n",
            "Total params: 1,256,523\n",
            "Trainable params: 1,256,523\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hescIc7Enavm",
        "outputId": "8d162441-7f23-48de-ebbb-2de0f2193cc5"
      },
      "source": [
        "from sklearn.utils import class_weight\n",
        "class_weight = class_weight.compute_sample_weight(\"balanced\", np.unique(y_train_labels))\n",
        "num_epochs =10\n",
        "batch_size = 128\n",
        "history_SMOTELSTM = modelSMOTELSTM.fit(X_sm, y_sm,\n",
        "                    batch_size=batch_size,\n",
        "                    epochs=num_epochs,\n",
        "                    verbose=2,\n",
        "                    #class_weight=class_weight,\n",
        "                    validation_data = [X_val_pad, y_testDL])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "117/117 - 18s - loss: 0.9197 - accuracy: 0.5574 - val_loss: 0.0000e+00 - val_accuracy: 0.0000e+00\n",
            "Epoch 2/10\n",
            "117/117 - 14s - loss: 0.6091 - accuracy: 0.7610 - val_loss: 0.0000e+00 - val_accuracy: 0.0000e+00\n",
            "Epoch 3/10\n",
            "117/117 - 14s - loss: 0.4171 - accuracy: 0.8501 - val_loss: 0.0000e+00 - val_accuracy: 0.0000e+00\n",
            "Epoch 4/10\n",
            "117/117 - 14s - loss: 0.3203 - accuracy: 0.8902 - val_loss: 0.0000e+00 - val_accuracy: 0.0000e+00\n",
            "Epoch 5/10\n",
            "117/117 - 14s - loss: 0.2620 - accuracy: 0.9151 - val_loss: 0.0000e+00 - val_accuracy: 0.0000e+00\n",
            "Epoch 6/10\n",
            "117/117 - 14s - loss: 0.2234 - accuracy: 0.9295 - val_loss: 0.0000e+00 - val_accuracy: 0.0000e+00\n",
            "Epoch 7/10\n",
            "117/117 - 14s - loss: 0.1894 - accuracy: 0.9406 - val_loss: 0.0000e+00 - val_accuracy: 0.0000e+00\n",
            "Epoch 8/10\n",
            "117/117 - 14s - loss: 0.1727 - accuracy: 0.9471 - val_loss: 0.0000e+00 - val_accuracy: 0.0000e+00\n",
            "Epoch 9/10\n",
            "117/117 - 14s - loss: 0.1524 - accuracy: 0.9528 - val_loss: 0.0000e+00 - val_accuracy: 0.0000e+00\n",
            "Epoch 10/10\n",
            "117/117 - 14s - loss: 0.1403 - accuracy: 0.9566 - val_loss: 0.0000e+00 - val_accuracy: 0.0000e+00\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mqFKWfKioHh2",
        "outputId": "416d8843-1af2-443f-f1d5-2d33445b6079"
      },
      "source": [
        "scoreLSTM1,accLSTM1= modelSMOTELSTM.evaluate(X_test_pad, y_testDL, \n",
        "                          batch_size = batch_size, verbose = 2)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "26/26 - 1s - loss: 0.0976 - accuracy: 0.9727\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "87OuCG1HorHr",
        "outputId": "ebe8f129-0725-4549-d9e6-2ba7695ceea7"
      },
      "source": [
        "modelLSTM.save(\"modelSMOTELSTM.h5\")\n",
        "print(\"Saved model to disk\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Saved model to disk\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "En1xfxHzowk-",
        "outputId": "61dca44b-2cac-44e0-d9aa-111a14f05d7b"
      },
      "source": [
        "def predict_DLSMOTELSTM(s):\n",
        "  s = sent_tokenize(s)\n",
        "  text_labels = encoder.classes_\n",
        "  X_tokens = tokenizer_obj.texts_to_sequences(s)\n",
        "  X_pad = pad_sequences(X_tokens, maxlen=max_length, padding='post')\n",
        "  loaded_model= tf.keras.models.load_model('modelSMOTELSTM.h5')\n",
        "  predictions = model.predict(np.array(X_pad))\n",
        "  predicted_label = text_labels[np.argmax(predictions[0])]\n",
        "  if predicted_label == 1.0:\n",
        "    return ('none')  \n",
        "\n",
        "  elif predicted_label  == 2.0:\n",
        "      return('sexism')\n",
        "\n",
        "  elif predicted_label == 3.0:\n",
        "      return('racism')\n",
        "\n",
        "s = input('Enter tweet : ')\n",
        "print(predict_DL(s))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Enter tweet : i hate muslim\n",
            "WARNING:tensorflow:Layer gru will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n",
            "racism\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2tYIB6dxlRkL"
      },
      "source": [
        "# Evaluation\n",
        "\n",
        "\n",
        "*   Accuracy\n",
        "*   F-Score\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JNoWIRnpPfqi"
      },
      "source": [
        "# GUI using Anvil"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ckPytZcajOMv"
      },
      "source": [
        "from getpass import getpass\n",
        "uplink_key = getpass('Enter your Uplink key: ')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ovQEcaHmP1av"
      },
      "source": [
        "!pip install anvil-uplink"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QNt37m-mP5Gk"
      },
      "source": [
        "import anvil.server"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IAJl7F6iQJBC"
      },
      "source": [
        "anvil.server.connect(uplink_key)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UwPgH2ZfQQW1"
      },
      "source": [
        "@anvil.server.callable\n",
        "def predict_ml_svm_with_smote(sentence):\n",
        "    sent = sent_tokenize(sentence)\n",
        "    y = vector_transformer.transform(sent)\n",
        " #   y_pred = nb.predict(y)\n",
        "    loaded_model = pickle.load(open(filenameSVMSMOTE, 'rb'))\n",
        "    y_pred = loaded_model.predict(y)\n",
        "    if y_pred == 1:\n",
        "      return ('none')  \n",
        "\n",
        "    elif y_pred  == 2:\n",
        "        return('sexism')\n",
        "\n",
        "    elif y_pred == 3:\n",
        "        return('racism')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2-yjPc6DRHCA"
      },
      "source": [
        "# anvil.server.wait_forever()"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}